{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 🌲 Pinecone Vector Database Tutorial\n",
    "\n",
    "A comprehensive guide to building a semantic search system using the **Pinecone** vector database and **SentenceTransformers**.  \n",
    "This tutorial demonstrates how to store document embeddings and perform intelligent similarity searches.\n",
    "\n",
    "## 📋 Prerequisites\n",
    "\n",
    "Before starting, ensure you have:\n",
    "\n",
    "- A **Pinecone account** and **API key**\n",
    "- **Python 3.7+** installed\n",
    "- Required packages:\n",
    "  - `pinecone-client`\n",
    "  - `sentence-transformers`\n",
    "  - `python-dotenv`\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "! pip install pinecone-client sentence-transformers python-dotenv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 🚀 Implementation\n",
    "\n",
    "### 1. Import Required Libraries\n",
    "\n",
    "Start by importing all necessary libraries.  \n",
    "We'll use:\n",
    "\n",
    "- **Pinecone** for vector storage  \n",
    "- **SentenceTransformers** for creating embeddings  \n",
    "- **dotenv** for managing environment variables securely\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pinecone import Pinecone, ServerlessSpec\n",
    "from dotenv import load_dotenv\n",
    "from sentence_transformers import SentenceTransformer\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> 📝 **Note:** Make sure to create a `.env` file with your  \n",
    "> `PINECONE_API_KEY=your_api_key_here`\n",
    "\n",
    "### 2. Environment Setup and Pinecone Initialization\n",
    "\n",
    "Load your environment variables and establish a connection to Pinecone.  \n",
    "This keeps your API key secure and separate from your code.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load environment variables from .env file\n",
    "load_dotenv()\n",
    "\n",
    "# Get the API key from environment variables\n",
    "api_key = os.getenv('PINECONE_API_KEY')\n",
    "\n",
    "# Initialize Pinecone with the API key\n",
    "pc = Pinecone(api_key=api_key)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> 🔐 **Security Tip:** Never hardcode API keys in your source code.  \n",
    "> Always use environment variables.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Index Configuration and Creation\n",
    "\n",
    "Configure your vector index with appropriate dimensions and create it if it doesn't exist.  \n",
    "We're using a **serverless setup on AWS** for cost-effectiveness and scalability.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ℹ️ Index pinecone-tutorial already exists\n",
      "📊 Index stats: {'dimension': 384,\n",
      " 'index_fullness': 0.0,\n",
      " 'metric': 'cosine',\n",
      " 'namespaces': {'': {'vector_count': 10}},\n",
      " 'total_vector_count': 10,\n",
      " 'vector_type': 'dense'}\n"
     ]
    }
   ],
   "source": [
    "# Index name and config\n",
    "index_name = \"pinecone-tutorial\"\n",
    "dimension = 384  # Dimension for all-MiniLM-L6-v2 model\n",
    "\n",
    "# Step 1: Check and create index using ServerlessSpec\n",
    "if index_name not in [index['name'] for index in pc.list_indexes()]:\n",
    "    pc.create_index(\n",
    "        name=index_name,\n",
    "        dimension=dimension,\n",
    "        metric=\"cosine\",  # Cosine similarity for text embeddings\n",
    "        spec=ServerlessSpec(cloud='aws', region='us-east-1')\n",
    "    )\n",
    "    print(f\"✅ Created index: {index_name}\")\n",
    "else:\n",
    "    print(f\"ℹ️ Index {index_name} already exists\")\n",
    "\n",
    "# Connect to the index\n",
    "index = pc.Index(index_name)\n",
    "print(f\"📊 Index stats: {index.describe_index_stats()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 🔑 Key Points:\n",
    "\n",
    "- **Dimension 384**: Matches the output size of the `all-MiniLM-L6-v2` model  \n",
    "- **Cosine metric**: Best for text similarity comparisons  \n",
    "- **Serverless**: Pay-per-use pricing model\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. Sample Documents and Model Initialization\n",
    "\n",
    "Define a diverse set of sample documents covering various tech topics  \n",
    "and initialize the SentenceTransformer model that will convert text to vector embeddings."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "documents = [\n",
    "    \"The quick brown fox jumps over the lazy dog\",\n",
    "    \"Artificial intelligence is transforming technology\",\n",
    "    \"Python is a popular programming language\",\n",
    "    \"Machine learning models require large datasets\",\n",
    "    \"Vector databases enable fast similarity search\",\n",
    "    \"Natural language processing analyzes text data\",\n",
    "    \"Deep learning uses neural networks\",\n",
    "    \"Data science combines statistics and programming\",\n",
    "    \"Cloud computing provides scalable infrastructure\",\n",
    "    \"Software development involves writing code\"\n",
    "]\n",
    "\n",
    "# Initialize the sentence transformer model\n",
    "model = SentenceTransformer(\"sentence-transformers/all-MiniLM-L6-v2\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> 🤖 **Model Choice:** `all-MiniLM-L6-v2` is lightweight, fast, and produces high-quality embeddings  \n",
    "> for general text similarity tasks.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5. Generate Embeddings and Prepare Data\n",
    "\n",
    "Transform your text documents into numerical vectors that capture their semantic meaning,  \n",
    "then format them for Pinecone storage with metadata.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate embeddings for all documents\n",
    "embeddings = model.encode(documents).tolist()\n",
    "\n",
    "# Prepare data structure for Pinecone upsert\n",
    "to_upsert = [\n",
    "    {\n",
    "        \"id\": f\"doc{i}\",                    # Unique identifier\n",
    "        \"values\": embeddings[i],            # Vector embedding\n",
    "        \"metadata\": {\"text\": documents[i]}  # Original text for retrieval\n",
    "    }\n",
    "    for i in range(len(documents))\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> **📊 Data Structure:**\n",
    "> - **ID**: Unique identifier for each document\n",
    "> - **Values**: 384-dimensional vector embedding\n",
    "> - **Metadata**: Store original text for easy retrieval\n",
    "\n",
    "### 6. Insert Documents into Pinecone\n",
    "\n",
    "Upload your prepared vectors to the Pinecone index. This operation is called \"upsert\" because it inserts new vectors or updates existing ones."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Documents inserted successfully.\n",
      "📈 Index stats after upload: {'dimension': 384,\n",
      " 'index_fullness': 0.0,\n",
      " 'metric': 'cosine',\n",
      " 'namespaces': {'': {'vector_count': 10}},\n",
      " 'total_vector_count': 10,\n",
      " 'vector_type': 'dense'}\n"
     ]
    }
   ],
   "source": [
    "# Upsert vectors to Pinecone index\n",
    "index.upsert(vectors=to_upsert)\n",
    "\n",
    "print(\"✅ Documents inserted successfully.\")\n",
    "print(f\"📈 Index stats after upload: {index.describe_index_stats()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> **⚡ Performance:** Pinecone handles indexing automatically, optimizing for fast similarity searches.\n",
    "\n",
    "### 7. Perform Similarity Search\n",
    "\n",
    "Query your vector database with natural language and retrieve the most semantically similar documents based on cosine similarity."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Pinecone Query: 'What is AI and machine learning?'\n",
      "\n",
      "🏆 Top 3 most similar documents:\n",
      "--------------------------------------------------\n",
      "1. 📊 Similarity Score: 0.532\n",
      "   📄 Text: Artificial intelligence is transforming technology\n",
      "\n",
      "2. 📊 Similarity Score: 0.438\n",
      "   📄 Text: Deep learning uses neural networks\n",
      "\n",
      "3. 📊 Similarity Score: 0.366\n",
      "   📄 Text: Data science combines statistics and programming\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Define search query\n",
    "query = \"What is AI and machine learning?\"\n",
    "\n",
    "# Convert query to embedding using the same model\n",
    "query_embedding = model.encode([query])\n",
    "\n",
    "# Search for similar documents\n",
    "search_results = index.query(\n",
    "    vector=query_embedding.tolist(),\n",
    "    top_k=3,                    # Return top 3 matches\n",
    "    include_metadata=True       # Include original text\n",
    ")\n",
    "\n",
    "# Display results\n",
    "print(f\"\\n🔍 Pinecone Query: '{query}'\")\n",
    "print(\"\\n🏆 Top 3 most similar documents:\")\n",
    "print(\"-\" * 50)\n",
    "\n",
    "for i, match in enumerate(search_results['matches']):\n",
    "    score = match['score']\n",
    "    text = match['metadata']['text']\n",
    "    \n",
    "    print(f\"{i+1}. 📊 Similarity Score: {score:.3f}\")\n",
    "    print(f\"   📄 Text: {text}\")\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 🎯 Expected Output\n",
    "\n",
    "When you run this code, you should see output similar to:\n",
    "\n",
    "```\n",
    "✅ Created index: pinecone-tutorial\n",
    "📊 Index stats: {'dimension': 384, 'index_fullness': 0.0, 'namespaces': {}}\n",
    "✅ Documents inserted successfully.\n",
    "📈 Index stats after upload: {'dimension': 384, 'index_fullness': 0.0, 'namespaces': {'': {'vector_count': 10}}}\n",
    "\n",
    "🔍 Pinecone Query: 'What is AI and machine learning?'\n",
    "\n",
    "🏆 Top 3 most similar documents:\n",
    "--------------------------------------------------\n",
    "1. 📊 Similarity Score: 0.689\n",
    "   📄 Text: Artificial intelligence is transforming technology\n",
    "\n",
    "2. 📊 Similarity Score: 0.623\n",
    "   📄 Text: Machine learning models require large datasets\n",
    "\n",
    "3. 📊 Similarity Score: 0.521\n",
    "   📄 Text: Deep learning uses neural networks\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 🔧 Advanced Usage\n",
    "\n",
    "### Batch Processing\n",
    "For larger datasets, process documents in batches:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 100\n",
    "for i in range(0, len(documents), batch_size):\n",
    "    batch = to_upsert[i:i+batch_size]\n",
    "    index.upsert(vectors=batch)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Filtering with Metadata\n",
    "Add more metadata for advanced filtering:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Enhanced metadata\n",
    "to_upsert = [\n",
    "    {\n",
    "        \"id\": f\"doc{i}\",\n",
    "        \"values\": embeddings[i],\n",
    "        \"metadata\": {\n",
    "            \"text\": documents[i],\n",
    "            \"category\": \"technology\",\n",
    "            \"source\": \"tutorial\"\n",
    "        }\n",
    "    }\n",
    "    for i in range(len(documents))\n",
    "]\n",
    "\n",
    "# Query with filters\n",
    "search_results = index.query(\n",
    "    vector=query_embedding.tolist(),\n",
    "    top_k=3,\n",
    "    include_metadata=True,\n",
    "    filter={\"category\": \"technology\"}\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 🛠️ Troubleshooting\n",
    "\n",
    "| Issue | Solution |\n",
    "|-------|----------|\n",
    "| API Key Error | Ensure your `.env` file contains `PINECONE_API_KEY=your_key` |\n",
    "| Dimension Mismatch | Verify model output dimensions match index configuration |\n",
    "| Index Not Found | Check index name spelling and creation status |\n",
    "| Slow Queries | Consider using namespaces for better organization |\n",
    "\n",
    "---\n",
    "\n",
    "## 📚 Additional Resources\n",
    "\n",
    "- [Pinecone Documentation](https://docs.pinecone.io/)\n",
    "- [Sentence Transformers Models](https://huggingface.co/sentence-transformers)\n",
    "- [Vector Database Concepts](https://www.pinecone.io/learn/vector-database/)\n",
    "\n",
    "---\n",
    "\n",
    "## 🎉 Next Steps\n",
    "\n",
    "1. **Scale Up**: Try with larger document collections\n",
    "2. **Fine-tune**: Experiment with different embedding models\n",
    "3. **Production**: Implement error handling and logging\n",
    "4. **Optimize**: Use namespaces and metadata filtering for complex queries\n",
    "\n",
    "Happy vector searching! 🚀"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Youtube_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
