{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ChromaDB Setup and Collection Creation\n",
    "\n",
    "## Overview\n",
    "This section demonstrates how to initialize a ChromaDB client and create your first vector database collection. ChromaDB is a vector database that allows you to store and query high-dimensional vectors efficiently.\n",
    "\n",
    "## Key Components\n",
    "\n",
    "### Client Initialization\n",
    "The process begins by creating a ChromaDB client instance. This client serves as the main interface for interacting with the database and managing collections.\n",
    "\n",
    "### Collection Creation\n",
    "A collection is created with specific parameters:\n",
    "- **Name**: A unique identifier for the collection (\"my_documents\")\n",
    "- **Metadata**: Additional information describing the collection's purpose\n",
    "- **Description**: A human-readable description explaining what the collection contains\n",
    "\n",
    "### Verification\n",
    "After creation, the system confirms:\n",
    "- The collection was successfully created\n",
    "- The collection name is properly set\n",
    "- The initial document count (which should be zero for a new collection)\n",
    "\n",
    "## Purpose\n",
    "This setup establishes the foundation for storing and retrieving document embeddings. The collection acts as a container where you can store documents along with their vector representations, enabling semantic search capabilities.\n",
    "\n",
    "## Benefits\n",
    "- **Organized Storage**: Collections help organize different types of documents\n",
    "- **Metadata Support**: Additional information can be stored alongside documents\n",
    "- **Scalability**: ChromaDB handles the underlying vector storage efficiently"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Required Libraries\n",
    "! pip install chromadb sentence-transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Created collection: my_documents\n",
      "Collection count: 0\n"
     ]
    }
   ],
   "source": [
    "import chromadb\n",
    "from sentence_transformers import SentenceTransformer\n",
    "import numpy as np\n",
    "\n",
    "# Initialize ChromaDB client\n",
    "client = chromadb.Client()\n",
    "\n",
    "# Create a collection (think of it as a table)\n",
    "collection = client.create_collection(\n",
    "    name=\"my_documents\",\n",
    "    metadata={\"description\": \"My first vector database\"}\n",
    ")\n",
    "\n",
    "print(f\"Created collection: {collection.name}\")\n",
    "print(f\"Collection count: {collection.count()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Document Processing and Embedding Generation\n",
    "\n",
    "## Overview\n",
    "This section covers the process of converting text documents into numerical vectors (embeddings) and storing them in the ChromaDB collection. This transformation enables semantic similarity search.\n",
    "\n",
    "## Sample Document Collection\n",
    "The process starts with a diverse set of sample documents covering various technology topics:\n",
    "- Programming languages and development\n",
    "- Artificial intelligence and machine learning\n",
    "- Data science and analytics\n",
    "- Cloud computing infrastructure\n",
    "- Natural language processing\n",
    "\n",
    "## Embedding Model\n",
    "A pre-trained sentence transformer model is utilized for generating embeddings:\n",
    "- **Model Type**: all-MiniLM-L6-v2\n",
    "- **Purpose**: Converts text into high-dimensional numerical vectors\n",
    "- **Advantage**: Captures semantic meaning of text for similarity comparisons\n",
    "\n",
    "## Embedding Generation Process\n",
    "The transformation process involves:\n",
    "1. **Loading the Model**: Initialize the sentence transformer\n",
    "2. **Text Processing**: Convert each document into a numerical vector\n",
    "3. **Dimension Verification**: Confirm the embedding dimensions are consistent\n",
    "4. **Progress Tracking**: Monitor the embedding generation process\n",
    "\n",
    "## Database Storage\n",
    "Documents are stored with multiple components:\n",
    "- **Document Text**: Original text content\n",
    "- **Embeddings**: Numerical vector representations\n",
    "- **Unique IDs**: Identifiers for each document\n",
    "- **Metadata**: Additional information including source and index\n",
    "\n",
    "## Results\n",
    "The process concludes by confirming:\n",
    "- Total number of embeddings generated\n",
    "- Vector dimensions for each embedding\n",
    "- Successful storage in the database\n",
    "- Final document count in the collection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating embeddings...\n",
      "Generated 40 embeddings of dimension 384\n",
      "Added 40 documents to the database\n"
     ]
    }
   ],
   "source": [
    "# Sample documents for our database\n",
    "documents = [\n",
    "    \"The quick brown fox jumps over the lazy dog\",\n",
    "    \"Artificial intelligence is transforming technology\",\n",
    "    \"Python is a popular programming language\",\n",
    "    \"Machine learning models require large datasets\",\n",
    "    \"Vector databases enable fast similarity search\",\n",
    "    \"Natural language processing analyzes text data\",\n",
    "    \"Deep learning uses neural networks\",\n",
    "    \"Data science combines statistics and programming\",\n",
    "    \"Cloud computing provides scalable infrastructure\",\n",
    "    \"Software development involves writing code\",\n",
    "]\n",
    "\n",
    "# Load sentence transformer model\n",
    "model = SentenceTransformer('all-MiniLM-L6-v2')\n",
    "\n",
    "# Generate embeddings\n",
    "print(\"Generating embeddings...\")\n",
    "embeddings = model.encode(documents)\n",
    "print(f\"Generated {len(embeddings)} embeddings of dimension {embeddings.shape[1]}\")\n",
    "\n",
    "# Create IDs for our documents\n",
    "ids = [f\"doc_{i}\" for i in range(len(documents))]\n",
    "\n",
    "# Add documents to ChromaDB\n",
    "collection.add(\n",
    "    documents=documents,\n",
    "    embeddings=embeddings.tolist(),\n",
    "    ids=ids,\n",
    "    metadatas=[{\"source\": \"sample\", \"index\": i} for i in range(len(documents))]\n",
    ")\n",
    "\n",
    "print(f\"Added {collection.count()} documents to the database\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Vector Search and Similarity Querying\n",
    "\n",
    "## Overview\n",
    "This section demonstrates how to perform semantic search using vector similarity. The system can find documents that are conceptually similar to a query, even if they don't share exact keywords.\n",
    "\n",
    "## Query Processing\n",
    "The search process begins with a natural language query about artificial intelligence and machine learning. This query undergoes the same transformation process as the stored documents.\n",
    "\n",
    "## Embedding Generation for Query\n",
    "The query text is converted into a numerical vector using the same sentence transformer model that was used for the document embeddings. This ensures consistency in the vector space representation.\n",
    "\n",
    "## Similarity Search Execution\n",
    "The database performs a similarity search with specific parameters:\n",
    "- **Query Vector**: The numerical representation of the search query\n",
    "- **Result Limit**: Number of most similar documents to return (top 3)\n",
    "- **Included Data**: Specifies what information to return (documents, distances, metadata)\n",
    "\n",
    "## Search Algorithm\n",
    "The system uses vector similarity metrics to:\n",
    "- Compare the query embedding with all stored document embeddings\n",
    "- Calculate distance/similarity scores\n",
    "- Rank documents by relevance\n",
    "- Return the most similar matches\n",
    "\n",
    "## Results Presentation\n",
    "The search results include:\n",
    "- **Distance Scores**: Numerical values indicating similarity (lower = more similar)\n",
    "- **Original Documents**: The actual text content of matching documents\n",
    "- **Ranking**: Documents ordered by relevance to the query\n",
    "\n",
    "## Semantic Understanding\n",
    "The search demonstrates semantic understanding by finding relevant documents that discuss:\n",
    "- Artificial intelligence concepts\n",
    "- Machine learning topics\n",
    "- Related technology themes\n",
    "\n",
    "This approach goes beyond keyword matching to understand the meaning and context of the query."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Query: What is AI and machine learning?\n",
      "\n",
      "Top 3 similar documents:\n",
      "1. Distance: 0.937\n",
      "   Document: Artificial intelligence is transforming technology\n",
      "\n",
      "2. Distance: 1.125\n",
      "   Document: Deep learning uses neural networks\n",
      "\n",
      "3. Distance: 1.145\n",
      "   Document: Computer vision enables machines to understand visual information\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Search query\n",
    "query = \"What is AI and machine learning?\"\n",
    "\n",
    "# Generate embedding for query\n",
    "query_embedding = model.encode([query])\n",
    "\n",
    "# Search the database\n",
    "results = collection.query(\n",
    "    query_embeddings=query_embedding.tolist(),\n",
    "    n_results=3,\n",
    "    include=['documents', 'distances', 'metadatas']\n",
    ")\n",
    "\n",
    "print(f\"\\nQuery: {query}\")\n",
    "print(\"\\nTop 3 similar documents:\")\n",
    "for i, (doc, distance) in enumerate(zip(results['documents'][0], results['distances'][0])):\n",
    "    print(f\"{i+1}. Distance: {distance:.3f}\")\n",
    "    print(f\"   Document: {doc}\")\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Youtube_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
